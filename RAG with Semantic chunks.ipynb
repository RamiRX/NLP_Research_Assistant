{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9de7f2f9379e4ba485f079dbd2a12222":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6696ac1c16b49b083fbd15d8486e03a","IPY_MODEL_59261ffdc42642cbb75ec793b1c65060","IPY_MODEL_2df59750b71b4744988226edc0852fd1"],"layout":"IPY_MODEL_d6a5f2f0df2d428ea07c8d97aee34761"}},"d6696ac1c16b49b083fbd15d8486e03a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f5672dbc3ad4a64b03174824a88438c","placeholder":"​","style":"IPY_MODEL_77e27b828c1343568e2aca48a4124d35","value":"Loading checkpoint shards: 100%"}},"59261ffdc42642cbb75ec793b1c65060":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6db6ab781c8b4bdbaa7fcee113214a90","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ec0c50f07f54f9faa0937e36bbbd99b","value":3}},"2df59750b71b4744988226edc0852fd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5487a87c1064345ad66214005c68f5d","placeholder":"​","style":"IPY_MODEL_78cc4d9194b94b34a8bd18f406a469b2","value":" 3/3 [00:23&lt;00:00, 23.94s/it]"}},"d6a5f2f0df2d428ea07c8d97aee34761":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f5672dbc3ad4a64b03174824a88438c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77e27b828c1343568e2aca48a4124d35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6db6ab781c8b4bdbaa7fcee113214a90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ec0c50f07f54f9faa0937e36bbbd99b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5487a87c1064345ad66214005c68f5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78cc4d9194b94b34a8bd18f406a469b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Enviroment Setup","metadata":{"id":"MOv1RC9iItEc"}},{"cell_type":"code","source":"!pip install arxiv pymupdf sentence-transformers transformers accelerate\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDywxe5jIn8j","outputId":"a545a3a5-9057-4860-b049-2cb48fa32926","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:03:06.238461Z","iopub.execute_input":"2025-12-24T17:03:06.238710Z","iopub.status.idle":"2025-12-24T17:03:15.270104Z","shell.execute_reply.started":"2025-12-24T17:03:06.238674Z","shell.execute_reply":"2025-12-24T17:03:15.269377Z"}},"outputs":[{"name":"stdout","text":"Collecting arxiv\n  Downloading arxiv-2.3.1-py3-none-any.whl.metadata (5.2 kB)\nCollecting pymupdf\n  Downloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\nCollecting feedparser~=6.0.10 (from arxiv)\n  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: requests~=2.32.0 in /usr/local/lib/python3.12/dist-packages (from arxiv) (2.32.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\nCollecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (2.6.2)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests~=2.32.0->arxiv) (2025.11.12)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nDownloading arxiv-2.3.1-py3-none-any.whl (11 kB)\nDownloading pymupdf-1.26.7-cp310-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=62e373e0d07a2bd6e512679efa22a074f5ad1f8e2273a1aeaa19e39c06ae7815\n  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\nSuccessfully built sgmllib3k\nInstalling collected packages: sgmllib3k, pymupdf, feedparser, arxiv\nSuccessfully installed arxiv-2.3.1 feedparser-6.0.12 pymupdf-1.26.7 sgmllib3k-1.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Download NLP Papers from arXiv (Controlled Corpus)\n\n\n","metadata":{"id":"4sw20dIXI7MD"}},{"cell_type":"code","source":"import arxiv, os, re\nfrom tqdm import tqdm\n\nBASE_DIR = \"arxiv_pdfs\"\nNLP_DIR = os.path.join(BASE_DIR, \"nlp_related\")\nos.makedirs(NLP_DIR, exist_ok=True)\n\ndef safe_filename(s):\n    return re.sub(r\"[^a-zA-Z0-9_-]+\", \"_\", s)[:80]\n\ndef download_pdf(result, out_dir):\n    filename = safe_filename(result.entry_id.split(\"/\")[-1]) + \".pdf\"\n    try:\n        result.download_pdf(dirpath=out_dir, filename=filename)\n        return os.path.join(out_dir, filename)\n    except:\n        return None\n\ndef fetch_nlp_pdfs(limit=20):\n    results = arxiv.Search(\n        query=\"cs.CL\",\n        max_results=limit * 3,\n        sort_by=arxiv.SortCriterion.Relevance\n    )\n\n    papers = []\n\n    for r in tqdm(results.results(), desc=\"Downloading NLP PDFs\"):\n        if len(r.summary) < 50:\n            continue\n\n        path = download_pdf(r, NLP_DIR)\n        if not path:\n            continue\n\n        papers.append({\n            \"paper_id\": r.entry_id.split(\"/\")[-1],\n            \"title\": r.title,\n            \"abstract\": r.summary,\n            \"pdf_path\": path,\n            \"source\": \"arxiv\",\n            \"category\": \"cs.CL\"\n        })\n\n        if len(papers) >= limit:\n            break\n\n    return papers\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PYfZteH7I6yM","outputId":"109499e8-6e06-41ce-be00-add6e86e54c3","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:03:33.357908Z","iopub.execute_input":"2025-12-24T17:03:33.358536Z","iopub.status.idle":"2025-12-24T17:03:36.956295Z","shell.execute_reply.started":"2025-12-24T17:03:33.358495Z","shell.execute_reply":"2025-12-24T17:03:36.955692Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/777180358.py:26: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n  for r in tqdm(results.results(), desc=\"Downloading NLP PDFs\"):\nDownloading NLP PDFs: 19it [00:03,  5.45it/s]\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Load SciBERT Classifier (Gate)","metadata":{"id":"6cfW2jQ-JD57"}},{"cell_type":"code","source":"!pip install -q gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:06:25.508748Z","iopub.execute_input":"2025-12-24T17:06:25.509328Z","iopub.status.idle":"2025-12-24T17:06:28.521037Z","shell.execute_reply.started":"2025-12-24T17:06:25.509294Z","shell.execute_reply":"2025-12-24T17:06:28.520016Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport zipfile\nimport gdown\nimport os\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# 1. Handle Google Drive Download\n# Extract the ID from your URL: 1-uf26t8kUTh60O16q8eVGdaeD9oOHlzY\ndrive_id = \"1-uf26t8kUTh60O16q8eVGdaeD9oOHlzY\"\nzip_output = \"scibert_model.zip\"\nextract_path = \"./scibert_nlp_classifier\"\n\n# Download using gdown (handles large file warnings automatically)\nif not os.path.exists(zip_output):\n    url = f'https://drive.google.com/uc?id={drive_id}'\n    gdown.download(url, zip_output, quiet=False)\n\n# 2. Extract the ZIP\nif not os.path.exists(extract_path):\n    with zipfile.ZipFile(zip_output, \"r\") as z:\n        z.extractall(extract_path)\n    print(f\"Model extracted to {extract_path}\")\n\n# 3. Load Model and Tokenizer\n# Note: Ensure the files (config.json, pytorch_model.bin) are directly in extract_path\ntokenizer_scibert = AutoTokenizer.from_pretrained(extract_path)\nmodel_scibert = AutoModelForSequenceClassification.from_pretrained(extract_path).to(DEVICE)\nmodel_scibert.eval()\n\nlabel_map = {0: \"not_nlp\", 1: \"nlp_related\"}\n\nprint(f\"Model successfully loaded on {DEVICE}\")","metadata":{"id":"qP2QIPJyJBNb","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:06:34.108931Z","iopub.execute_input":"2025-12-24T17:06:34.109670Z","iopub.status.idle":"2025-12-24T17:06:58.635851Z","shell.execute_reply.started":"2025-12-24T17:06:34.109616Z","shell.execute_reply":"2025-12-24T17:06:58.635097Z"}},"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1-uf26t8kUTh60O16q8eVGdaeD9oOHlzY\nFrom (redirected): https://drive.google.com/uc?id=1-uf26t8kUTh60O16q8eVGdaeD9oOHlzY&confirm=t&uuid=bb8fc0ed-3aac-43fd-b1f8-581cd96da3c8\nTo: /kaggle/working/scibert_model.zip\n100%|██████████| 409M/409M [00:03<00:00, 105MB/s]  \n","output_type":"stream"},{"name":"stdout","text":"Model extracted to ./scibert_nlp_classifier\n","output_type":"stream"},{"name":"stderr","text":"2025-12-24 17:06:45.426378: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766596005.612753      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766596005.663739      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766596006.104397      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766596006.104434      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766596006.104436      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766596006.104439      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Model successfully loaded on cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# PDF Text Extraction (No NLP Preprocessing)","metadata":{"id":"FOuI1fLlJn0D"}},{"cell_type":"code","source":"import fitz  # PyMuPDF\n\ndef extract_pdf_text(path):\n    doc = fitz.open(path)\n    pages = []\n    for page in doc:\n        txt = page.get_text()\n        if txt:\n            pages.append(txt)\n    return \"\\n\".join(pages)\n\n\ndef classify_with_scibert(text):\n    inputs = tokenizer_scibert(\n        text,\n        truncation=True,\n        max_length=256,\n        return_tensors=\"pt\"\n    ).to(DEVICE)\n\n    with torch.no_grad():\n        logits = model_scibert(**inputs).logits\n\n    return label_map[int(torch.argmax(logits))]\n","metadata":{"id":"BTOQjRzAJqBb","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:57:10.523180Z","iopub.execute_input":"2025-12-24T17:57:10.523488Z","iopub.status.idle":"2025-12-24T17:57:10.528842Z","shell.execute_reply.started":"2025-12-24T17:57:10.523461Z","shell.execute_reply":"2025-12-24T17:57:10.528048Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# Section-aware chunking","metadata":{}},{"cell_type":"code","source":"def extract_structured_sections(text):\n    \"\"\"\n    Extract scientifically meaningful sections from a paper.\n    This avoids naive keyword filtering.\n    \"\"\"\n    sections = []\n    current = []\n    header = None\n\n    for line in text.split(\"\\n\"):\n        if re.match(r\"^\\s*(abstract|introduction|background|model|method|formalism|discussion)\", line.lower()):\n            if current:\n                sections.append((\"other\", \"\\n\".join(current)))\n                current = []\n            header = line.strip()\n        current.append(line)\n\n    if current:\n        sections.append((header if header else \"other\", \"\\n\".join(current)))\n\n    return sections\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:43:12.884343Z","iopub.execute_input":"2025-12-24T17:43:12.884663Z","iopub.status.idle":"2025-12-24T17:43:12.889858Z","shell.execute_reply.started":"2025-12-24T17:43:12.884620Z","shell.execute_reply":"2025-12-24T17:43:12.889152Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Apply SciBERT Gate","metadata":{"id":"xhMSJkApJr2D"}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"accepted_docs = {}\n\nfor path in tqdm(pdf_paths, desc=\"SciBERT filtering\"):\n    text = extract_pdf_text(path)\n    if len(text) < 500:\n        continue\n\n    label = classify_with_scibert(text)\n    if label == \"nlp_related\":\n        title = os.path.basename(path).replace(\".pdf\", \"\")\n        accepted_docs[title] = text\n\nlen(accepted_docs)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jW20veH5Ju3z","outputId":"c50ee704-7d09-4c35-a606-6fc217d49ed7","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:01:53.191126Z","iopub.execute_input":"2025-12-24T18:01:53.191911Z","iopub.status.idle":"2025-12-24T18:01:55.985084Z","shell.execute_reply.started":"2025-12-24T18:01:53.191875Z","shell.execute_reply":"2025-12-24T18:01:55.984407Z"}},"outputs":[{"name":"stderr","text":"SciBERT filtering: 100%|██████████| 20/20 [00:02<00:00,  7.18it/s]\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}],"execution_count":38},{"cell_type":"markdown","source":"# Chunking","metadata":{"id":"TnBm1lr3J3Tr"}},{"cell_type":"markdown","source":"# Semantic Chunking","metadata":{}},{"cell_type":"code","source":"import nltk\ndef chunk_text(text, max_words=200):\n    sentences = nltk.sent_tokenize(text)\n    chunks, current = [], []\n\n    for s in sentences:\n        current.append(s)\n        if len(\" \".join(current).split()) >= max_words:\n            chunks.append(\" \".join(current))\n            current = []\n\n    if current:\n        chunks.append(\" \".join(current))\n\n    return chunks\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:05:46.417176Z","iopub.execute_input":"2025-12-24T18:05:46.417471Z","iopub.status.idle":"2025-12-24T18:05:46.422413Z","shell.execute_reply.started":"2025-12-24T18:05:46.417443Z","shell.execute_reply":"2025-12-24T18:05:46.421689Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"# Build SBERT Index (MPNet)","metadata":{"id":"5GK0KRv9KJL7"}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sentence_transformers.util import cos_sim\n\nretriever = SentenceTransformer(\"all-mpnet-base-v2\")\n\nchunks = []\nmeta = []\n\nfor title, text in accepted_docs.items():\n    for i, ch in enumerate(chunk_text(text)):\n        chunks.append(ch)\n        meta.append({\"title\": title, \"chunk_id\": i})\n\nchunk_embeddings = retriever.encode(chunks, convert_to_tensor=True)\n","metadata":{"id":"FeAuLfUXKPBL","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:05:47.937778Z","iopub.execute_input":"2025-12-24T18:05:47.938556Z","iopub.status.idle":"2025-12-24T18:06:10.306447Z","shell.execute_reply.started":"2025-12-24T18:05:47.938523Z","shell.execute_reply":"2025-12-24T18:06:10.305584Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"# Diversified Retrieval","metadata":{"id":"NhEAtyyoKeu0"}},{"cell_type":"code","source":"def retrieve(query, top_k=3, max_per_doc=1):\n    q_emb = retriever.encode(query, convert_to_tensor=True)\n    scores = cos_sim(q_emb, chunk_embeddings)[0]\n    ranked = torch.argsort(scores, descending=True)\n\n    selected, per_doc = [], {}\n\n    for idx in ranked:\n        idx = int(idx)\n        title = meta[idx][\"title\"]\n        if per_doc.get(title, 0) >= max_per_doc:\n            continue\n\n        selected.append({\n            \"text\": chunks[idx],\n            \"title\": title,\n            \"chunk_id\": meta[idx][\"chunk_id\"],\n            \"score\": float(scores[idx])\n        })\n\n        per_doc[title] = per_doc.get(title, 0) + 1\n        if len(selected) >= top_k:\n            break\n\n    return selected\n","metadata":{"id":"8yDtdrswKjdr","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:06:20.467333Z","iopub.execute_input":"2025-12-24T18:06:20.468088Z","iopub.status.idle":"2025-12-24T18:06:20.473761Z","shell.execute_reply.started":"2025-12-24T18:06:20.468058Z","shell.execute_reply":"2025-12-24T18:06:20.472925Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"# Utilities - croppping the text before it enters the LLM","metadata":{"id":"7bq-N-fhPtNL"}},{"cell_type":"code","source":"\n\ndef truncate_text(text, tokenizer, max_tokens=120):\n    \"\"\"\n    Truncate text to a fixed number of tokens\n    to avoid GPU/CPU memory explosion during generation.\n    \"\"\"\n    tokens = tokenizer.encode(text, add_special_tokens=False)\n    tokens = tokens[:max_tokens]\n    return tokenizer.decode(tokens)\n","metadata":{"id":"aW-ZRyvzP0wj","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:06:23.281350Z","iopub.execute_input":"2025-12-24T18:06:23.281698Z","iopub.status.idle":"2025-12-24T18:06:23.286492Z","shell.execute_reply.started":"2025-12-24T18:06:23.281659Z","shell.execute_reply":"2025-12-24T18:06:23.285688Z"}},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"# Evidence-based RAG","metadata":{"id":"sK6Mnw7FKn5D"}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForCausalLM\n\nllm_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\ntok = AutoTokenizer.from_pretrained(llm_name)\nllm = AutoModelForCausalLM.from_pretrained(\n    llm_name,\n    device_map=\"auto\",\n    torch_dtype=torch.float16\n)\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9de7f2f9379e4ba485f079dbd2a12222","d6696ac1c16b49b083fbd15d8486e03a","59261ffdc42642cbb75ec793b1c65060","2df59750b71b4744988226edc0852fd1","d6a5f2f0df2d428ea07c8d97aee34761","4f5672dbc3ad4a64b03174824a88438c","77e27b828c1343568e2aca48a4124d35","6db6ab781c8b4bdbaa7fcee113214a90","5ec0c50f07f54f9faa0937e36bbbd99b","d5487a87c1064345ad66214005c68f5d","78cc4d9194b94b34a8bd18f406a469b2"]},"id":"Jc-nwVE1KqLb","outputId":"c8061631-75ea-4f36-f74b-9c14cdf79fc1","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T17:08:15.298465Z","iopub.execute_input":"2025-12-24T17:08:15.299002Z","iopub.status.idle":"2025-12-24T17:09:25.645536Z","shell.execute_reply.started":"2025-12-24T17:08:15.298972Z","shell.execute_reply":"2025-12-24T17:09:25.644873Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4478fcf1b6ad42eba8c87ad052e7ed1e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7ad414ecb954e6181277fc3b0254332"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cf5bd4ae12a4d4f9b6d99842b21d7a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c69fad55caf546d498af3a016e3e4668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14eca85150340339b8ff40283753416"}},"metadata":{}},{"name":"stderr","text":"`torch_dtype` is deprecated! Use `dtype` instead!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70a0996f587d41d3a4b1c3baff73fa55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f61b893b02fd420183e8e8a2a98063da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f9044c6db5a433d8c284b2ca061d8f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a56a3b8f3fe4f97807ed798aef91752"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb7ad05367ed49fbaae12cc05d582ca6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8830c856d5db4062ad7b337fe066bbc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f804e69f78884f7e98277dbc78c523c9"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"def build_prompt(question, evidences):\n    ctx = \"\"\n    for i, e in enumerate(evidences, 1):\n        ctx += (\n            f\"[{i}] {e['title']}:\\n\"\n            f\"{truncate_text(e['text'], tok, max_tokens=120)}\\n\\n\"\n        )\n\n    return f\"\"\"\nYou are an academic assistant.\nAnswer the question strictly using the provided evidence.\nDo not use prior knowledge.\nalso You are an expert in compositional distributional semantics.\n\nAnswer the question using ONLY the provided evidence.\nFocus on:\n- how sentence meaning is computed\n- the role of linear maps and inner products\n- why tensor dimensionality does NOT grow with sentence length\n\n\nEvidence:\n{ctx}\n\nQuestion:\n{question}\n\nAnswer concisely and cite sources like [1], [2].\n\"\"\"\n","metadata":{"id":"ZGe51KkiSyRc","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:15:47.048619Z","iopub.execute_input":"2025-12-24T18:15:47.048987Z","iopub.status.idle":"2025-12-24T18:15:47.053877Z","shell.execute_reply.started":"2025-12-24T18:15:47.048947Z","shell.execute_reply":"2025-12-24T18:15:47.053154Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"# Final RAG answer","metadata":{"id":"scvUsey4K1U7"}},{"cell_type":"code","source":"from transformers import TextIteratorStreamer\nimport threading\n\ndef rag_answer(question):\n    evidences = retrieve(question, top_k=3, max_per_doc=1)\n    prompt = build_prompt(question, evidences)\n\n    inputs = tok(\n        prompt,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024\n    ).to(llm.device)\n\n    streamer = TextIteratorStreamer(tok, skip_special_tokens=True)\n\n    generation_kwargs = dict(\n        **inputs,\n        max_new_tokens=150,\n        do_sample=False,\n        streamer=streamer\n    )\n\n    thread = threading.Thread(target=llm.generate, kwargs=generation_kwargs)\n    thread.start()\n\n    print(\"\\nANSWER (streaming):\\n\")\n    output = \"\"\n    for token in streamer:\n        print(token, end=\"\", flush=True)\n        output += token\n\n    return output, evidences\n","metadata":{"id":"l9B2YTIUK4vz","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:07:18.329132Z","iopub.execute_input":"2025-12-24T18:07:18.329832Z","iopub.status.idle":"2025-12-24T18:07:18.335237Z","shell.execute_reply.started":"2025-12-24T18:07:18.329800Z","shell.execute_reply":"2025-12-24T18:07:18.334524Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"# Test the RAG","metadata":{"id":"BPLE5WffODzT"}},{"cell_type":"code","source":"question = \"\"\"\nHow does the proposed compositional distributional model represent sentence meaning,\nand why does it avoid the dimensionality explosion problem of tensor-based approaches?\n\"\"\"\n","metadata":{"id":"QheSxS5ROG1b","trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:06:35.337411Z","iopub.execute_input":"2025-12-24T18:06:35.338054Z","iopub.status.idle":"2025-12-24T18:06:35.341263Z","shell.execute_reply.started":"2025-12-24T18:06:35.338025Z","shell.execute_reply":"2025-12-24T18:06:35.340517Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"answer, evidences = rag_answer(question)\n\nprint(\"\\nEVIDENCE USED:\\n\")\nfor i, e in enumerate(evidences, 1):\n    print(f\"[{i}] {e['title']} | chunk {e['chunk_id']} | score={e['score']:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-24T18:15:52.867610Z","iopub.execute_input":"2025-12-24T18:15:52.868211Z","iopub.status.idle":"2025-12-24T18:16:02.293227Z","shell.execute_reply.started":"2025-12-24T18:15:52.868173Z","shell.execute_reply":"2025-12-24T18:16:02.292614Z"}},"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nANSWER (streaming):\n\n\nYou are an academic assistant.\nAnswer the question strictly using the provided evidence.\nDo not use prior knowledge.\nalso You are an expert in compositional distributional semantics.\n\nAnswer the question using ONLY the provided evidence.\nFocus on:\n- how sentence meaning is computed\n- the role of linear maps and inner products\n- why tensor dimensionality does NOT grow with sentence length\n\n\nEvidence:\n[1] 1101_0309v1:\narXiv:1101.0309v1  [cs.CL]  31 Dec 2010\nConcrete Sentence Spaces for Compositional Distributional\nModels of Meaning\nEdward Grefenstette∗, Mehrnoosh Sadrzadeh∗, Stephen Clark†, Bob Coecke∗, Stephen Pulman∗\n∗Oxford University Computing Laboratory, †University of Cambridge Computer Laboratory\nfirstname.lastname@comlab.ox.ac.uk, step\n\n[2] 1106_4058v1:\nWe\nprovide a general algorithm for building (or indeed\nlearning) these matrices from the corpus. The implementation is evaluated against the task\nprovided by Mitchell and Lapata (2008) for disam-\nbiguating intransitive verbs, as well as a similar new\nexperiment for transitive verbs. Our model improves\non the best method evaluated in Mitchell and Lapata\n(2008) and offers promising results for the transitive\ncase, demonstrating its scalability in comparison to\nthat of other models. But\n\n[3] 1105_1702v2:\nA Compositional Distributional Semantics,\nTwo Concrete Constructions,\nand some Experimental Evaluations\nMehrnoosh Sadrzadeh⋆and Edward Grefenstette\nDepartment of Computer Science, University of Oxford, UK. mehrnoosh.sadrzadeh@cs.ox.ac.uk\nedward.grefenstette@cs.ox.ac.uk\nAbstract. We provide an overview of the hybrid compositional distribu-\ntional model of meaning, developed in [6], which is based on\n\n\n\nQuestion:\n\nHow does the proposed compositional distributional model represent sentence meaning,\nand why does it avoid the dimensionality explosion problem of tensor-based approaches?\n\n\nAnswer concisely and cite sources like [1], [2].\n\nAnswer:\n\nThe compositional distributional model of meaning, as proposed in [1], [6], represents sentence meaning through a combination of distributional vectors for words and linear maps between these vectors. The model uses a tensor product of word vectors to compute the meaning of a sentence, but it avoids the dimensionality explosion problem of tensor-based approaches by applying a linear map to reduce the tensor dimensionality to the vector space of the sentence meaning [1]. The algorithm for building or learning these matrices from a corpus is provided in [2].\nEVIDENCE USED:\n\n[1] 1101_0309v1 | chunk 0 | score=0.8501\n[2] 1106_4058v1 | chunk 3 | score=0.7699\n[3] 1105_1702v2 | chunk 0 | score=0.7656\n","output_type":"stream"}],"execution_count":62}]}